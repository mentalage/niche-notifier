# 🚀 Notify Niche 기능 확장 제안

현재 시스템은 RSS 피드를 수집하고 Discord로 알림을 보내는 기본 기능을 제공합니다.
아래는 단계별로 구현 가능한 확장 기능 제안입니다.

---

## 🎯 Tier 1: 즉시 구현 가능 (Low Complexity)

### 1.1 키워드 필터링 시스템

**목적**: 관심 있는 키워드가 포함된 기사만 알림 받기

**구현 방법**:

- `config.py`에 `KEYWORDS` 리스트 추가
- 제목 또는 본문에 키워드가 포함된 경우만 알림
- 키워드별로 우선순위 설정 가능

```python
# config.py 예시
KEYWORDS = {
    "high_priority": ["AI", "ChatGPT", "머신러닝"],
    "medium_priority": ["Python", "Docker", "AWS"],
    "exclude": ["광고", "스폰서"]
}
```

**예상 소요 시간**: 1-2시간
**난이도**: ⭐

---

### 1.2 다중 알림 채널 지원

**목적**: Discord 외에 Slack, Telegram, Email 등 다양한 채널로 알림

**구현 방법**:

- `notifier.py`를 추상화하여 여러 Notifier 클래스 생성
- 환경 변수로 활성화할 채널 선택

```python
# 지원 예정 채널
- Discord Webhook ✅ (이미 구현됨)
- Slack Webhook
- Telegram Bot API
- Resend API (Email)
```

**예상 소요 시간**: 3-4시간
**난이도**: ⭐⭐

---

### 1.3 피드별 스케줄링

**목적**: 각 RSS 피드마다 다른 체크 주기 설정

**구현 방법**:

- `FEED_URLS`를 딕셔너리로 변경
- 각 피드에 `schedule` 메타데이터 추가
- GitHub Actions에서 여러 워크플로우 실행

```python
FEED_URLS = {
    "https://hnrss.org/show": {
        "schedule": "hourly",
        "name": "Hacker News Show"
    },
    "https://rss.blog.naver.com/ranto28.xml": {
        "schedule": "daily",
        "name": "메르의 블로그"
    }
}
```

**예상 소요 시간**: 2-3시간
**난이도**: ⭐⭐

---

## 🔥 Tier 2: AI 기반 고급 기능 (Medium Complexity)

### 2.1 AI 기반 기사 요약

**목적**: 긴 기사를 읽지 않아도 핵심 내용 파악

**구현 방법**:

- OpenAI GPT-4o-mini 또는 Gemini API 사용
- RSS 본문을 3-5줄로 요약
- Discord 알림에 요약 포함

**추가 환경 변수**:

- `OPENAI_API_KEY` 또는 `GEMINI_API_KEY`

**예상 비용**: 월 $5-10 (소규모 사용 시)
**예상 소요 시간**: 4-5시간
**난이도**: ⭐⭐⭐

---

### 2.2 AI 기반 관심도 점수

**목적**: 내 관심사에 맞는 기사에 점수를 매겨 우선순위 부여

**구현 방법**:

- 사용자의 관심사 프로필 작성 (예: "AI, 웹 개발, 스타트업에 관심")
- AI가 기사와 프로필을 비교해 0-10점 스코어링
- 7점 이상만 알림 또는 점수별로 다른 채널에 전송

**예상 비용**: 월 $10-20
**예상 소요 시간**: 6-8시간
**난이도**: ⭐⭐⭐⭐

---

### 2.3 자동 태그 분류

**목적**: AI가 자동으로 기사에 태그 부여 (예: #AI, #Backend, #DevOps)

**구현 방법**:

- AI에게 기사 분석 요청
- DB에 태그 저장
- 태그별로 필터링 가능

**예상 소요 시간**: 4-5시간
**난이도**: ⭐⭐⭐

---

## 🏗️ Tier 3: 인프라 확장 (High Complexity)

### 3.1 웹 대시보드

**목적**: 수집된 기사를 웹에서 관리하고 검색

**구현 방법**:

- Next.js 또는 Flask로 간단한 웹앱 구축
- Supabase 데이터 시각화
- 읽음/안 읽음 표시, 즐겨찾기 기능

**배포 옵션**:

- Vercel (무료)
- CloudFlare Pages (무료)
- GitHub Pages (정적 사이트의 경우)

**예상 소요 시간**: 12-16시간
**난이도**: ⭐⭐⭐⭐⭐

---

### 3.2 검색 및 아카이브 시스템

**목적**: 과거에 수집한 기사를 빠르게 검색

**구현 방법**:

- Supabase Full-Text Search 활용
- 또는 Algolia / MeiliSearch 연동
- REST API로 검색 기능 제공

**예상 소요 시간**: 8-10시간
**난이도**: ⭐⭐⭐⭐

---

### 3.3 통계 및 분석 대시보드

**목적**: 어떤 피드가 가장 활발한지, 어떤 키워드가 자주 나오는지 분석

**구현 방법**:

- Supabase에서 집계 쿼리
- Chart.js 또는 Recharts로 시각화
- 주간/월간 리포트 자동 생성

**예상 소요 시간**: 10-12시간
**난이도**: ⭐⭐⭐⭐

---

## 📊 추천 로드맵

### Phase 1: Quick Wins (1-2주)

1. ✅ 키워드 필터링 시스템
2. ✅ 다중 알림 채널 지원 (Slack, Telegram 중 택 1)
3. ✅ 피드별 메타데이터 관리

### Phase 2: AI Enhancement (2-3주)

1. ✅ AI 기사 요약
2. ✅ 자동 태그 분류

### Phase 3: Platform Building (1-2개월)

1. ✅ 웹 대시보드
2. ✅ 검색 기능
3. ✅ 통계 시각화

---

## 💡 즉시 시작 가능한 Quick Win

**가장 추천하는 첫 번째 확장 기능**: **키워드 필터링 시스템**

**이유**:

- 구현이 간단함 (1-2시간)
- 즉각적인 가치 제공
- 기존 코드 구조에 최소한의 변경만 필요
- 추가 비용 없음

**다음 단계 제안**:

1. 키워드 필터링 구현
2. Slack 또는 Telegram 알림 추가
3. AI 요약 기능 실험
4. 사용자 피드백 기반으로 웹 대시보드 고려

---

## 🎨 보너스 아이디어

### 읽기 모드 최적화

- Discord 메시지에 Reader Mode 링크 추가 (예: 12ft.io, archive.is)
- 광고 없는 깔끔한 기사 읽기

### 소셜 통합

- Twitter/X에서 트렌딩 토픽 크로스 체크
- Reddit에서 관련 토론 링크 추가

### 스마트 다이제스트

- 하루의 모든 기사를 하나의 요약 메시지로 묶기
- 오전/오후 다이제스트 옵션

---

## 📝 다음 단계

어떤 기능부터 구현하고 싶으신가요? 제안드린 기능 중에서 선택하시면 구체적인 구현 계획을 작성하겠습니다!

**추천 순서**:

1. 🥇 키워드 필터링 (가장 빠른 가치)
2. 🥈 AI 요약 (가장 큰 임팩트)
3. 🥉 웹 대시보드 (장기 비전)
